<!DOCTYPE html>
<html>
<head>
  <title>Phone Voice Input</title>
  <style>
    body { font-family: Arial; text-align: center; margin-top: 40px; background: #f4f6f9; }
    h1 { font-size: 36px; }
    #status { font-size: 20px; margin-bottom: 10px; font-weight: bold; }
    #textArea { width: 90%; height: 150px; margin-top: 15px; font-size: 18px; padding: 10px; }
    button { padding: 12px 25px; font-size: 18px; margin: 10px; cursor: pointer; border-radius: 6px; border: none; }
    #micButton { background: #007bff; color:white; }
    #micButton.listening { background: red; animation: pulse 1s infinite; }
    #sendButton { background: green; color:white; }
    #restartButton { background: #ffc107; color:black; }
    #silenceOptions { margin-top: 15px; }
    @keyframes pulse { 0% { opacity:1 } 50% { opacity:0.4 } 100% { opacity:1 } }
  </style>
</head>
<body>

<h1>üé§ Phone Voice Input</h1>
<div id="status">Waiting for voice input...</div>

<textarea id="textArea" placeholder="Your speech will appear here..." ></textarea><br>

<button id="micButton">üéô Start/Stop Listening</button>
<button id="sendButton">Send</button>
<button id="restartButton">Restart Text</button>

<div id="silenceOptions" style="display:none;">
  <p>Stopped due to silence. Choose:</p>
  <button id="continueButton">Continue same message</button>
  <button id="startOverButton">Start over</button>
</div>

<script>
  const webhookUrl = "https://n8n.knotastain.com/webhook-test/format-message"; // your n8n webhook
  const params = new URLSearchParams(window.location.search);
  const sessionToken = params.get("session") || "DEFAULTSESSION";

  let recognition;
  let listening = false;
  let currentText = "";
  let silenceTimer;

  const textArea = document.getElementById("textArea");
  const statusDiv = document.getElementById("status");
  const micButton = document.getElementById("micButton");
  const sendButton = document.getElementById("sendButton");
  const restartButton = document.getElementById("restartButton");
  const silenceOptions = document.getElementById("silenceOptions");
  const continueButton = document.getElementById("continueButton");
  const startOverButton = document.getElementById("startOverButton");

  function resetSilenceTimer() {
    if (silenceTimer) clearTimeout(silenceTimer);
    silenceTimer = setTimeout(() => {
      stopListening();
      silenceOptions.style.display = "block";
      statusDiv.innerText = "‚è∏ Stopped due to 5s of silence";
    }, 5000); // 5 seconds of silence
  }

  if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.lang = "en-US";
    recognition.interimResults = true;
    recognition.continuous = true;

    recognition.onresult = (event) => {
      let transcript = "";
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        transcript += event.results[i][0].transcript;
      }
      textArea.value = currentText + transcript;
      resetSilenceTimer();
    };

    recognition.onerror = (event) => {
      statusDiv.innerText = "‚ùå Error: " + event.error;
      listening = false;
      micButton.classList.remove("listening");
    };

    recognition.onend = () => {
      if (listening) recognition.start();
    };
  } else {
    alert("Your browser does not support Speech Recognition");
  }

  function startListening() {
    if (!recognition) return;
    listening = true;
    recognition.start();
    statusDiv.innerText = "üî¥ Listening...";
    micButton.classList.add("listening");
    silenceOptions.style.display = "none";
    resetSilenceTimer();
  }

  function stopListening() {
    listening = false;
    if (recognition) recognition.stop();
    micButton.classList.remove("listening");
    if (currentText === "") statusDiv.innerText = "‚úÖ Paused";
  }

  micButton.addEventListener("click", () => {
    if (listening) stopListening();
    else startListening();
  });

  restartButton.addEventListener("click", () => {
    textArea.value = "";
    currentText = "";
    statusDiv.innerText = "‚úèÔ∏è Text restarted";
    silenceOptions.style.display = "none";
  });

  continueButton.addEventListener("click", () => {
    currentText = textArea.value;
    startListening();
  });

  startOverButton.addEventListener("click", () => {
    textArea.value = "";
    currentText = "";
    startListening();
  });

  sendButton.addEventListener("click", async () => {
    const textToSend = textArea.value.trim();
    if (!textToSend) {
      alert("No text to send!");
      return;
    }

    try {
      await fetch(webhookUrl, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          text: textToSend,
          session: sessionToken
        })
      });
      statusDiv.innerText = "‚úÖ Sent to n8n!";
      currentText += textToSend + "\n"; // keep current text for further dictation
      // Keep listening if it was already listening
      if (!listening) startListening();
    } catch (err) {
      console.error(err);
      statusDiv.innerText = "‚ùå Error sending to n8n";
    }
  });
</script>

</body>
</html>
